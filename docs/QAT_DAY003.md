# QAT_DAY003: Who Decides Value — The Irreducible Role of Humans

## Abstract

Even in fully automated systems, value does not define itself.
This chapter clarifies the role of humans in a research framework
where strategies are generated and evaluated automatically.

## 1. Automation Has a Boundary

Automated systems can:

- Generate candidates
- Evaluate performance
- Optimize metrics

They cannot define **what should matter**.

Value selection remains irreducibly human.

## 2. The Illusion of Objective Optimization

Metrics appear objective,
but every metric encodes a preference:

- Accuracy over diversity
- Speed over stability
- Memory over flexibility

Choosing metrics is a value judgment.

## 3. Human Role Redefined

In this research, I do not:

- Design quantization rules
- Interpret internal representations
- Select winning strategies manually

I do:

- Define evaluation axes
- Decide acceptable trade-offs
- Determine deployment relevance

This is not control.
It is **responsibility**.

## 4. Comparison with MIN

This clarifies the contrast between research routes:

- **MIN**: Observe failure modes directly on hardware  
  → Discover where systems break

- **QAT**: Define competition rules  
  → Discover which strategies survive

MIN explores *boundaries by contact*.  
QAT explores *boundaries by selection*.

## 5. Why This Matters Now

As AI systems gain autonomy,
human involvement shifts from execution to judgment.

This research treats that shift not as a problem,
but as a design principle.

## 6. Transition

Once value axes are defined,
they must be formalized into measurable criteria.

That formalization is the subject of the next chapter.
